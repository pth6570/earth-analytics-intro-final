{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.3.0'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 9;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.1/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.1/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.0.min.js\", \"https://cdn.holoviz.org/panel/1.3.1/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      Bokeh = root.Bokeh;\n      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      if (!reloading && (!bokeh_loaded || is_dev)) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='p1002'>\n",
       "  <div id=\"b6e9d0c9-a28b-4347-83e7-87281d4138b2\" data-root-id=\"p1002\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"9f9dd9e5-4c0e-4b23-8b23-e46e1549f14f\":{\"version\":\"3.3.0\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"p1002\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"p1003\",\"attributes\":{\"plot_id\":\"p1002\",\"comm_id\":\"125ea26c9d8e4c32b68aff2a152f819b\",\"client_comm_id\":\"463472afa2d8411eadb3e5f57bddeec8\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"toggle_value1\",\"properties\":[{\"name\":\"active_icons\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"options\",\"kind\":\"Any\",\"default\":{\"type\":\"map\",\"entries\":[[\"favorite\",\"heart\"]]}},{\"name\":\"value\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"_reactions\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"_base_url\",\"kind\":\"Any\",\"default\":\"https://tabler-icons.io/static/tabler-icons/icons/\"}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"value\",\"kind\":\"Any\",\"default\":null},{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"9f9dd9e5-4c0e-4b23-8b23-e46e1549f14f\",\"roots\":{\"p1002\":\"b6e9d0c9-a28b-4347-83e7-87281d4138b2\"},\"root_ids\":[\"p1002\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  const is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1\n",
       "  function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version && !is_dev) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "p1002"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import io\n",
    "import math \n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import earthpy as et\n",
    "import earthpy.appeears as etapp\n",
    "import geopandas as gpd\n",
    "import hvplot.xarray  \n",
    "import hvplot.pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import rioxarray as rxr\n",
    "import rioxarray.merge as rxrmerge\n",
    "import requests\n",
    "import xarray as xr\n",
    "import zipfile\n",
    "from xrspatial import aspect\n",
    "from xrspatial import slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directory\n",
    "data_dir = os.path.join(et.io.HOME, et.io.DATA_NAME, 'final_project')\n",
    "if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "\n",
    "# # Get original working directory\n",
    "if 'owd' not in globals():\n",
    "    owd = os.getcwd()\n",
    "\n",
    "# Create plot directory\n",
    "plot_dir = os.path.join(owd, \"plots\")\n",
    "if not os.path.exists(plot_dir):\n",
    "        os.makedirs(plot_dir)   \n",
    "    \n",
    "# Define utm zone\n",
    "utm = 32613"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code adapted from: https://medium.com/@loldja/reading-shapefile-zips-from-a-url-in-python-3-93ea8d727856\n",
    "# Create directory\n",
    "grassland_url = ('https://data.fs.usda.gov/geodata/edw/'\n",
    "                 'edw_resources/shp/S_USA.NationalGrassland.zip'\n",
    ")\n",
    "# Request data from url\n",
    "grassland_request = requests.get(grassland_url)\n",
    "grassland_zip = zipfile.ZipFile(io.BytesIO(grassland_request.content))\n",
    "\n",
    "# Extract files from zip and save to directory\n",
    "grassland_zip.extractall(\n",
    "    path=os.path.join(data_dir, 'national-grassland')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import shapefile\n",
    "grassland_gdf = gpd.read_file(os.path.join(\n",
    "    data_dir, 'national-grassland', 'S_USA.NationalGrassland.shp')\n",
    "    )\n",
    "\n",
    "# Get selected grasslands\n",
    "select_grassland_gdf = (\n",
    "    grassland_gdf\n",
    "    .set_index('GRASSLANDN')\n",
    "    .loc[['Comanche National Grassland', 'Pawnee National Grassland']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Comanche National Grassland :\n",
      "mean_ph_lat3637_lon-105-104.tif is already downloaded\n",
      "mean_ph_lat3637_lon-104-103.tif is already downloaded\n",
      "mean_ph_lat3637_lon-103-102.tif is already downloaded\n",
      "mean_ph_lat3738_lon-105-104.tif is already downloaded\n",
      "mean_ph_lat3738_lon-104-103.tif is already downloaded\n",
      "mean_ph_lat3738_lon-103-102.tif is already downloaded\n",
      "A merged soil data array already exists.\n",
      "\n",
      " Pawnee National Grassland :\n",
      "mean_ph_lat4041_lon-105-104.tif is already downloaded\n",
      "mean_ph_lat4041_lon-104-103.tif is already downloaded\n",
      "mean_ph_lat4142_lon-105-104.tif is already downloaded\n",
      "mean_ph_lat4142_lon-104-103.tif is already downloaded\n",
      "A merged soil data array already exists.\n"
     ]
    }
   ],
   "source": [
    "def get_polaris_data(data_directory, input_gdf, index_col_name):\n",
    "    \"\"\"\n",
    "    This function downloads Polaris soil data for the extent of each\n",
    "    row in a geodataframe and creates a merged data array for each.\n",
    "    Downloaded data is saved in individual folders for each row. Merged\n",
    "    data arrays for each row are saved in \"Merged_files\" subfolder.\n",
    "\n",
    "    Paramters\n",
    "    ----------\n",
    "    data_directory : path\n",
    "        The path to the data directory. A sub-directory will be created\n",
    "        within this directory for the soil data downloads.\n",
    "\n",
    "    input_gdf: geopandas.GeoDataFrame\n",
    "        A geodataframe that contains the areas of interest. Polaris soil\n",
    "        data will be downloaded according to the bounds of each row in\n",
    "        the dataframe.\n",
    "\n",
    "    index_col_name: string\n",
    "        A string containing the name of the geoDataFrame column that\n",
    "        should be used as the index. This index will be used to name\n",
    "        output files.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    output_lst: list of data arrays\n",
    "        Returns a list of data arrays representing the merged Polaris\n",
    "        tif data for each row in the input geodataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # Set index to specified index column\n",
    "    input_gdf = input_gdf.reset_index().set_index(index_col_name)\n",
    "\n",
    "    # Create dataframe of bounds of each gdf row\n",
    "    bound_pd = pd.concat([input_gdf.bounds], axis=1)\n",
    "\n",
    "    file_list = []\n",
    "\n",
    "    # Loop through each row in the boundary dataframe\n",
    "    for ind in bound_pd.index:\n",
    "        print(\"\\n\", ind, \":\")\n",
    "        # Define and round min and max longitude and latitudes\n",
    "        min_lon = math.floor(bound_pd[\"minx\"][ind])\n",
    "        max_lon = math.ceil(bound_pd[\"maxx\"][ind])\n",
    "        min_lat = math.floor(bound_pd[\"miny\"][ind])\n",
    "        max_lat = math.ceil(bound_pd[\"maxy\"][ind])\n",
    "        # Define range\n",
    "        lat_range = range(min_lat, max_lat)\n",
    "        lon_range = range(min_lon, max_lon)\n",
    "\n",
    "        # Create template for polaris url path\n",
    "        polaris_template_url = (\n",
    "            \"http://hydrology.cee.duke.edu/POLARIS/PROPERTIES/v1.0/\"\n",
    "            \"{0}/{1}/{2}/lat{3}{4}_lon{5}{6}.tif\"\n",
    "        )\n",
    "        # Create template for file names\n",
    "        polaris_template_name = \"mean_ph_lat{0}{1}_lon{2}{3}.tif\"\n",
    "\n",
    "        # Create sub-directory for soil data\n",
    "        soil_dir = os.path.join(data_directory, \"soil_data\")\n",
    "        if not os.path.exists(soil_dir):\n",
    "            os.makedirs(soil_dir)\n",
    "\n",
    "        # Create sub-folders for each row's data\n",
    "        soil_row_dir = os.path.join(soil_dir, str(ind).replace(\" \", \"_\"))\n",
    "        if not os.path.exists(soil_row_dir):\n",
    "            os.makedirs(soil_row_dir)\n",
    "\n",
    "        # Create sub-folder for merged data arrays\n",
    "        soil_merged_dir = os.path.join(soil_dir, \"Merged_tifs\")\n",
    "        if not os.path.exists(soil_merged_dir):\n",
    "            os.makedirs(soil_merged_dir)\n",
    "\n",
    "        # For each latitude and longitude in the extent, download file\n",
    "        for lat in lat_range:\n",
    "            for lon in lon_range:\n",
    "                # Define url for each data file in extent\n",
    "                url = polaris_template_url.format(\n",
    "                    \"ph\",\n",
    "                    \"mean\",\n",
    "                    \"60_100\",\n",
    "                    str(lat),\n",
    "                    str(lat + 1),\n",
    "                    str(lon),\n",
    "                    str(lon + 1),\n",
    "                )\n",
    "                # Define file name for each data file in extent\n",
    "                file_name = polaris_template_name.format(\n",
    "                    str(lat), str(lat + 1), str(lon), str(lon + 1)\n",
    "                )\n",
    "                # Check if tif file is in directory. Download if not.\n",
    "                file_name_path = os.path.join(soil_row_dir, file_name)\n",
    "                if not os.path.exists(file_name_path):\n",
    "                    print(file_name, \"does not exist. Downloading file\")\n",
    "                    r = requests.get(url, allow_redirects=True)\n",
    "                    open(file_name_path, \"wb\").write(r.content)\n",
    "                else:\n",
    "                    print(file_name, \"is already downloaded\")\n",
    "\n",
    "        # Define the name for the merged file\n",
    "        merge_template_name = \"{0}_merged_da.tif\"\n",
    "        merge_da_name = (\n",
    "            merge_template_name.format(str(ind)\n",
    "                                       .replace(\" \", \"_\"), \".tif\"))\n",
    "        # Merge arrays if the merged file does not exist\n",
    "        if not os.path.exists(os.path.join(soil_merged_dir, merge_da_name)):\n",
    "            print(\"Soil data is being merged.\")\n",
    "            tif_paths = glob(os.path.join(soil_row_dir, \"*.tif\"))\n",
    "            das = [rxr.open_rasterio(tif, masked=True) for tif in tif_paths]\n",
    "            merged_da = rxrmerge.merge_arrays(das)\n",
    "            merged_da.rio.to_raster(\n",
    "                os.path.join(soil_merged_dir, merge_da_name)\n",
    "                )\n",
    "            print(\"Merged soil file created.\")\n",
    "        # Otherwise, load existing merged file\n",
    "        else:\n",
    "            print(\"A merged soil data array already exists.\")\n",
    "            merged_da = rxr.open_rasterio(\n",
    "                os.path.join(soil_merged_dir, merge_da_name), masked=True\n",
    "            )\n",
    "\n",
    "        # Add file to list of tif files to return\n",
    "        file_list.append(os.path.join(soil_merged_dir, merge_da_name))\n",
    "\n",
    "    # Return files\n",
    "    output_lst = [rxr.open_rasterio(tif, masked=True).squeeze() \n",
    "                  for tif in file_list]\n",
    "    return output_lst\n",
    "\n",
    "\n",
    "comanche_pH_da, pawnee_pH_da = get_polaris_data(\n",
    "    data_dir, select_grassland_gdf, \"GRASSLANDN\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change projection of grassland data\n",
    "select_grassland_utm_gdf = select_grassland_gdf.to_crs(utm)\n",
    "\n",
    "# Clip pH files to bounds\n",
    "comanche_pH_da = (comanche_pH_da\n",
    "                  .rio.reproject(utm)\n",
    "                  .rio.clip_box(\n",
    "                      *select_grassland_utm_gdf\n",
    "                      .loc[['Comanche National Grassland']]\n",
    "                      .total_bounds)\n",
    ")\n",
    "pawnee_pH_da = (pawnee_pH_da\n",
    "                  .rio.reproject(utm)\n",
    "                  .rio.clip_box(\n",
    "                      *select_grassland_utm_gdf\n",
    "                      .loc[['Pawnee National Grassland']]\n",
    "                      .total_bounds)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change crs of selected grasslands\n",
    "select_grassland_gdf = select_grassland_gdf.to_crs(4326)\n",
    "\n",
    "# Download AppEEARS SRTM DEM data for full extent\n",
    "elevation_downloader = etapp.AppeearsDownloader(\n",
    "    download_key=\"SRTM_DEM\",\n",
    "    ea_dir=data_dir,\n",
    "    product=\"SRTMGL1_NC.003\",\n",
    "    layer=\"SRTMGL1_DEM\",\n",
    "    start_date=\"02-11\",\n",
    "    end_date=\"02-21\",\n",
    "    recurring=True,\n",
    "    year_range=[2000,2000],\n",
    "    polygon=select_grassland_gdf,\n",
    ")\n",
    "\n",
    "# Download files if the download directory does not exist\n",
    "if not os.path.exists(elevation_downloader.data_dir):\n",
    "    elevation_downloader.download_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read elevation data.\n",
    "for tif in glob(os.path.join(data_dir, 'SRTM_DEM',\n",
    "                'SRTMGL1_NC*',\n",
    "                '*.tif')):\n",
    "    elev_da = rxr.open_rasterio(tif, masked=True).squeeze()\n",
    "    elev_da.name = 'Elevation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_and_reproj_match(in_da, clip_gdf, match_da):\n",
    "    \"\"\"\n",
    "    This function clips a data array to a specificed extent and\n",
    "    harmonizes the array to match another data array.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_da: xarray.DataArray\n",
    "        Represents the data array that is to be clipped and reprojected\n",
    "\n",
    "    clip_gdf: geopandas.GeoDataFrame\n",
    "        The geodataframe to which the data input area should be clipped\n",
    "\n",
    "    match_da: xarray.DataArray\n",
    "        The data array for which the input data array should be\n",
    "        reprojected to match the resolution, projection, and region\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    clip_da: xarray.DataArray\n",
    "        A clipped and harmonized version of the input data array\n",
    "    \"\"\"\n",
    "    # Clip to extent of input and reproject match to specified array\n",
    "    clip_da = in_da.rio.clip_box(\n",
    "        *clip_gdf.to_crs(in_da.rio.crs).total_bounds\n",
    "    ).rio.reproject_match(match_da)\n",
    "\n",
    "    return clip_da\n",
    "\n",
    "\n",
    "# Run function for Pawnee and Comanche\n",
    "pawnee_elev_da = clip_and_reproj_match(\n",
    "    elev_da, select_grassland_gdf.loc[[\"Pawnee National Grassland\"]], \n",
    "    pawnee_pH_da\n",
    ")\n",
    "comanche_elev_da = clip_and_reproj_match(\n",
    "    elev_da, select_grassland_gdf.loc[[\"Comanche National Grassland\"]], \n",
    "    comanche_pH_da\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slope and Aspect\n",
    "def get_slope_and_aspect(elevation_da):\n",
    "    \"\"\"\n",
    "    This function returns the slope and aspect for an elevation data\n",
    "    array.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    elevation_da: xarray.DataArray\n",
    "        A data array containing elevation values. Must be in \n",
    "        projected coordinate system with units of meters.\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    slope_da: xarray.DataArray\n",
    "        A data array containing the slope values for the input raster\n",
    "        \n",
    "    aspect_da: xarray.DataArray\n",
    "        A data array containing the aspect values for the input raster\n",
    "    \"\"\"\n",
    "    slope_da = slope(elevation_da)\n",
    "    aspect_da = aspect(elevation_da)\n",
    "    return slope_da, aspect_da\n",
    "\n",
    "# Get slope and aspect for Pawnee and Comanche\n",
    "comanche_slope_da, comanche_aspect_da = get_slope_and_aspect(comanche_elev_da)\n",
    "pawnee_slope_da, pawnee_aspect_da = get_slope_and_aspect(pawnee_elev_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A MACA2 file for this scenario is already saved in the directory. Skipping download.\n",
      "A MACA2 file for this scenario is already saved in the directory. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "def download_maca2_data(data_directory, model, scenario, variable_abb, st_year, end_year):\n",
    "    \"\"\"\n",
    "    This function downloads MACA2 data for a specific model, scenario,\n",
    "    variable, and year range.\n",
    "\n",
    "    Paramters\n",
    "    ----------\n",
    "    data_directory: path\n",
    "        The path to the data directory where the MACA2 data will be \n",
    "        stored\n",
    "\n",
    "    model: string\n",
    "        Represents the selected MACA2 model that data will be downloaded \n",
    "        for. Acceptable values are: 'bcc-csm1-1', 'bcc-csm1-1-m',\n",
    "        'BNU-ESM', 'CanESM2', 'CCSM4', 'CNRM-CM5', 'CSIRO-Mk3-6-0',\n",
    "        'GFDL-ESM2G', 'GFDL-ESM2M', 'HadGEM2-CC365', 'HadGEM2-ES365',\n",
    "        'inmcm4', 'IPSL-CM5A-MR', 'IPSL-CM5A-LR', 'IPSL-CM5B-LR','MIROC5',\n",
    "        'MIROC-ESM', 'MIROC-ESM-CHEM','MRI-CGCM3', 'NorESM1-M'.\n",
    "\n",
    "    scenario: string\n",
    "        Represents the climate scenario that data will be downloaded for.\n",
    "        Must be 'rcp45', 'rcp85', or 'historical'.\n",
    "\n",
    "    variable_abb: string\n",
    "        The abbreviation for the climate variable that data will be \n",
    "        downloaded for. Acceptable values are: tasmax', 'tasmin', \n",
    "        'rhsmax', 'rhsmin', 'pr', 'rsds', 'uas', 'vas', 'huss'.\n",
    "\n",
    "    st_year: integer\n",
    "        A four-digit integer representing the start year for the data \n",
    "        download. Must be between 2006 and 2099 for rcp45 and rcp85, or \n",
    "        between 1950 and 2005 for historical scenarios.\n",
    "\n",
    "    end_year: integer\n",
    "        A four-digit integer representing the end year for the data \n",
    "        download. Must be between 2006 and 2099 for rcp45 and rcp85, or \n",
    "        between 1950 and 2005 for historical scenarios.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    clim_da: xarray.Dataset\n",
    "        Returns a dataset containing the downloaded MACA2 data\n",
    "\n",
    "    \"\"\"\n",
    "    # Check if model parameter is valid\n",
    "    model_lst = ['bcc-csm1-1', 'bcc-csm1-1-m',\n",
    "        'BNU-ESM', 'CanESM2', 'CCSM4', 'CNRM-CM5', 'CSIRO-Mk3-6-0',\n",
    "        'GFDL-ESM2G', 'GFDL-ESM2M', 'HadGEM2-CC365', 'HadGEM2-ES365',\n",
    "        'inmcm4', 'IPSL-CM5A-MR', 'IPSL-CM5A-LR', 'IPSL-CM5B-LR','MIROC5',\n",
    "        'MIROC-ESM', 'MIROC-ESM-CHEM','MRI-CGCM3', 'NorESM1-M']\n",
    "    if model not in model_lst:\n",
    "        raise ValueError(\"The listed model {0} is not valid.\"\n",
    "                         \"Check input\".format(model)\n",
    "                         )\n",
    "\n",
    "    # Define long variable names for MACA2 data\n",
    "    variables_long_list = ['precipitation', 'air_temperature', \n",
    "                      'air_temperature', 'relative_humidity',\n",
    "                      'relative_humidity', \n",
    "                      'surface_downwelling_shortwave_flux_in_air',\n",
    "                      'eastward_wind', \n",
    "                      'northward_wind',\n",
    "                      'specific_humidity'\n",
    "    ]\n",
    "\n",
    "    # Define abbreviated variable names for MACA2 data\n",
    "    variables_abb_lst = ['pr', 'tasmax', 'tasmin', 'rhsmin', 'rhsmax', \n",
    "                      'rsds', 'uas', 'vas', 'huss']\n",
    "    if variable_abb not in variables_abb_lst:\n",
    "        raise ValueError(\"The listed variable abbreviation {0} is not \"\n",
    "                        \"valid. Check value\".format(variable_abb)\n",
    "                         )\n",
    "\n",
    "    # Create dictionary to get variable long name\n",
    "    variables_dict = {variables_abb_lst[i]: variables_long_list[i] \n",
    "           for i in range(len(variables_long_list))}\n",
    "\n",
    "    # Create template for MACA url path\n",
    "    template_url = (\"http://thredds.northwestknowledge.net:8080\"\\\n",
    "                \"/thredds/ncss/agg_macav2metdata_{0}_{1}_r\"\\\n",
    "                \"{2}i1p1_{3}_{4}_CONUS_monthly.nc\"\\\n",
    "                \"?var={5}\"\\\n",
    "                \"&disableLLSubset=on\"\n",
    "                \"&disableProjSubset=on\"\n",
    "                \"&horizStride=1&time_start={6}-01-15T00%3A00%3A00Z\"\n",
    "                \"&time_end={7}-12-15T00%3A00%3A00Z\"\n",
    "                \"&timeStride=1\"\n",
    "                \"&accept=netcdf\"\n",
    "    )\n",
    "\n",
    "    # Define whether url value is r6i1p1 or r1i1p1\n",
    "    if model == \"CCSM4\":\n",
    "        value = 6\n",
    "    else:\n",
    "        value = 1\n",
    "    \n",
    "    # Define year range for scenario\n",
    "    if scenario == \"historical\":\n",
    "        year_range = \"1950_2005\"\n",
    "    else:\n",
    "        year_range = \"2006_2099\"\n",
    "    \n",
    "    # Create url for download\n",
    "    url = template_url.format(variable_abb,\n",
    "                              model,\n",
    "                              value,\n",
    "                              scenario,\n",
    "                              year_range,\n",
    "                              variables_dict.get(variable_abb),\n",
    "                              st_year,\n",
    "                              end_year\n",
    "                              )\n",
    "\n",
    "    # Make request to url\n",
    "    maca_response = requests.get(url)\n",
    "\n",
    "    # Create template for MACA2 file name\n",
    "    template_filename = (\"{0}_{1}_{2}_{3}to{4}.nc\"\n",
    "    )\n",
    "\n",
    "    # Generate file name for saving\n",
    "    file_path = os.path.join(data_directory, \n",
    "                             template_filename.format(model,\n",
    "                                                      scenario,\n",
    "                                                      variable_abb,\n",
    "                                                      st_year,\n",
    "                                                      end_year\n",
    "                                                      )\n",
    "    )\n",
    "    \n",
    "    # If this MACA2 data does not yet exist in directory, download\n",
    "    if not os.path.exists(file_path):\n",
    "        # Save data\n",
    "        with open(file_path, 'wb') as maca_file:\n",
    "            maca_file.write(maca_response.content)\n",
    "        print(\"Downloading data\")\n",
    "\n",
    "    # Otherwise skip download\n",
    "    else:\n",
    "        print(\"A MACA2 file for this scenario is already saved in the \"\n",
    "              \"directory. Skipping download.\")\n",
    "\n",
    "    # Open the dataset and return\n",
    "    clim_dataset = xr.open_dataset(file_path)\n",
    "    return clim_dataset\n",
    "\n",
    "CCSM4_rcp45_da = download_maca2_data(\n",
    "    data_dir, \"CCSM4\", \"rcp45\", \"pr\", 2050, 2050)\n",
    "    \n",
    "CCSM4_rcp85_da = download_maca2_data(\n",
    "    data_dir, \"CCSM4\", \"rcp85\", \"pr\", 2050, 2050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign coords & set spatial dimensions\n",
    "def maca2_assign_coords(xr_dataset):\n",
    "    \"\"\"\n",
    "    Modifies longitude coordinates for a dataset to convert from 0-360\n",
    "    to -180 to 180. Also converts the data to a data array and sets\n",
    "    the spatial dimensions and coordinate reference system.\n",
    "\n",
    "    Parameters\n",
    "    __________\n",
    "    xr_dataset: xarray.DataSet\n",
    "        A dataset for which coordinates need to be modified from 0 to\n",
    "        360, to -180 to 180\n",
    "    \n",
    "    Returns\n",
    "    out_da: xarray.DataArray\n",
    "        A data array for which the longitude coordinates have been\n",
    "        converted to -180 to 180\n",
    "    \"\"\"\n",
    "    # Get data variable name from xr_dataset\n",
    "    var_name = list(xr_dataset.keys())[0]\n",
    "    # Assign coordinates\n",
    "    xr_dataset = xr_dataset.assign_coords(lon =  xr_dataset.lon - 360, \n",
    "                                          inplace=True)\n",
    "    # Select data variable\n",
    "    out_da = xr_dataset[var_name]\n",
    "    # Change crs for data array\n",
    "    out_da.rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "    # Set spatial dimensions for data array\n",
    "    out_da.rio.set_spatial_dims('lon','lat',inplace=True)\n",
    "    return out_da\n",
    "\n",
    "CCSM4_rcp45_da = maca2_assign_coords(CCSM4_rcp45_da)\n",
    "CCSM4_rcp85_da = maca2_assign_coords(CCSM4_rcp85_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip and Reproject Match the Precipitation Data for Scenarios in Comanche\n",
    "comanche_CCSM4_rcp45_da = clip_and_reproj_match(\n",
    "    CCSM4_rcp45_da,\n",
    "    select_grassland_gdf.loc[[\"Comanche National Grassland\"]],\n",
    "    comanche_pH_da,\n",
    ")\n",
    "\n",
    "comanche_CCSM4_rcp85_da = clip_and_reproj_match(\n",
    "    CCSM4_rcp85_da,\n",
    "    select_grassland_gdf.loc[[\"Comanche National Grassland\"]],\n",
    "    comanche_pH_da,\n",
    ")\n",
    "\n",
    "# Clip and Reproject Match the Precipitation Data for Scenarios in Pawnee\n",
    "pawnee_CCSM4_rcp45_da = clip_and_reproj_match(\n",
    "    CCSM4_rcp45_da,\n",
    "    select_grassland_gdf.loc[[\"Pawnee National Grassland\"]],\n",
    "    pawnee_pH_da,\n",
    ")\n",
    "\n",
    "pawnee_CCSM4_rcp85_da = clip_and_reproj_match(\n",
    "    CCSM4_rcp85_da,\n",
    "    select_grassland_gdf.loc[[\"Pawnee National Grassland\"]],\n",
    "    pawnee_pH_da,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pawnee RCP 4.5 Model\n",
    "pawnee_rcp45_model = (\n",
    "    ( # Multiply data layers with suitability parameters applied\n",
    "        (pawnee_pH_da < 8)\n",
    "        * (pawnee_pH_da > 4.8)\n",
    "        * (pawnee_CCSM4_rcp45_da.mean(\"time\") < 45)\n",
    "        * (pawnee_CCSM4_rcp45_da.mean(\"time\") > 11)\n",
    "        * (pawnee_elev_da < 6500)\n",
    "        * (pawnee_aspect_da > 90)\n",
    "    ).hvplot(rasterize=True)\n",
    "    # Add grassland polygons\n",
    "    * select_grassland_utm_gdf.loc[[\"Pawnee National Grassland\"]].hvplot(\n",
    "        line_color=\"red\", color=None\n",
    "    )\n",
    ").opts(\n",
    "    xaxis=None,\n",
    "    yaxis=None,\n",
    "    title=(\"Pawnee Grassland Suitable\" \"Habitat (RCP 4.5 Scenario)\"),\n",
    ")\n",
    "\n",
    "# Save plot\n",
    "hvplot.save(pawnee_rcp45_model, \n",
    "            os.path.join(plot_dir, \"pawnee_rcp45_model.html\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pawnee RCP 4.5 Model\n",
    "pawnee_rcp85_model = (\n",
    "    ( # Multiply data layers with suitability parameters applied\n",
    "        (pawnee_pH_da < 8)\n",
    "        * (pawnee_pH_da > 4.8)\n",
    "        * (pawnee_CCSM4_rcp85_da.mean(\"time\") < 45)\n",
    "        * (pawnee_CCSM4_rcp85_da.mean(\"time\") > 11)\n",
    "        * (pawnee_elev_da < 6500)\n",
    "        * (pawnee_aspect_da > 90)\n",
    "    ).hvplot(rasterize=True)\n",
    "    # Add grassland polygons\n",
    "    * select_grassland_utm_gdf.loc[[\"Pawnee National Grassland\"]].hvplot(\n",
    "        line_color=\"red\", color=None\n",
    "    )\n",
    ").opts(\n",
    "    xaxis=None,\n",
    "    yaxis=None,\n",
    "    title=(\"Pawnee Grassland Suitable Habitat (RCP 8.5 Scenario)\"),\n",
    ")\n",
    "# Save plot\n",
    "hvplot.save(pawnee_rcp85_model, \n",
    "            os.path.join(plot_dir, \"pawnee_rcp85_model.html\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pawnee RCP 4.5 Model\n",
    "comanche_rcp45_model = (\n",
    "    (# Multiply data layers with suitability parameters applied\n",
    "        (comanche_pH_da < 8)\n",
    "        * (comanche_pH_da > 4.8)\n",
    "        * (comanche_CCSM4_rcp45_da.mean(\"time\") < 45)\n",
    "        * (comanche_CCSM4_rcp45_da.mean(\"time\") > 11)\n",
    "        * (comanche_elev_da < 6500)\n",
    "        * (comanche_aspect_da > 90)\n",
    "    ).hvplot(rasterize=True)\n",
    "    # Add grassland polygons\n",
    "    * select_grassland_utm_gdf.loc[[\"Comanche National Grassland\"]].hvplot(\n",
    "        line_color=\"red\", color=None\n",
    "    )\n",
    ").opts(\n",
    "    xaxis=None,\n",
    "    yaxis=None,\n",
    "    title=(\"Comanche Grassland Suitable Habitat (RCP 4.5 Scenario)\"),\n",
    ")\n",
    "# Save plot\n",
    "hvplot.save(comanche_rcp45_model, \n",
    "            os.path.join(plot_dir, \"comanche_rcp45_model.html\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pawnee RCP 4.5 Model\n",
    "comanche_rcp85_model = (\n",
    "    ( # Multiply data layers with suitability parameters applied\n",
    "        (comanche_pH_da < 8)\n",
    "        * (comanche_pH_da > 4.8)\n",
    "        * (comanche_CCSM4_rcp85_da.mean(\"time\") < 45)\n",
    "        * (comanche_CCSM4_rcp85_da.mean(\"time\") > 11)\n",
    "        * (comanche_elev_da < 6500)\n",
    "        * (comanche_aspect_da > 90)\n",
    "    ).hvplot(rasterize=True)\n",
    "    # Add grassland polygons\n",
    "    * select_grassland_utm_gdf.loc[[\"Comanche National Grassland\"]].hvplot(\n",
    "        line_color=\"red\", color=None\n",
    "    )\n",
    ").opts(\n",
    "    xaxis=None,\n",
    "    yaxis=None,\n",
    "    title=(\"Comanche Grassland Suitable Habitat (RCP 8.5 Scenario)\")\n",
    ")\n",
    "# Save plot\n",
    "hvplot.save(comanche_rcp85_model, \n",
    "            os.path.join(plot_dir, \"comanche_rcp85_model.html\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grassland_plot(plot_da, var, site, cmap_val, edge_color_text, title):\n",
    "    \"\"\"\n",
    "    This function is intended to create plots for the elevation, aspect, \n",
    "    soil, or climate data for Comanche and Pawnee grassland area. A png\n",
    "    plot is saved to the working directory\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    plot_da: xarray.DataArray\n",
    "        The data array that is to be plotted\n",
    "\n",
    "    var: string\n",
    "        A text field listing the name of the data element being examined;\n",
    "         Used to name the output plot\n",
    "    \n",
    "    site: string\n",
    "        A string indictating whether the site is Pawnee or Comanche\n",
    "    \n",
    "    cmap_val: string\n",
    "        A string indicating the cmap value to use in the plot\n",
    "\n",
    "    edge_color_text: string\n",
    "        The color to use as the grassland boundary in the plot\n",
    "    \n",
    "    title: string\n",
    "        The title to use in the plot\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Define names for plot components and output\n",
    "    plt_name = str(site) + str(var) + \"_fig\"\n",
    "    ax_name = str(site) + str(var) + \"_ax1\"\n",
    "    out_name=str(site) + \"_\" + str(var) + \"_plt.png\"\n",
    "    out_path =os.path.join(plot_dir, out_name)\n",
    "\n",
    "    # Define site name based on input paramters\n",
    "    if site.lower() == \"pawnee\":\n",
    "        full_site_name = \"Pawnee National Grassland\"\n",
    "    else:\n",
    "        full_site_name = \"Comanche National Grassland\"\n",
    "\n",
    "    # Create plot\n",
    "    plt_name, ax_name = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Add data array\n",
    "    plot_da.plot(ax=ax_name, cmap=cmap_val)\n",
    "\n",
    "    # Add grassland boundaries\n",
    "    select_grassland_utm_gdf.loc[[full_site_name]].plot(\n",
    "    ax=ax_name, facecolor=\"none\", edgecolor=edge_color_text, linewidth=0.5\n",
    "    )\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.close()\n",
    "    # Save plot\n",
    "    plt_name.savefig(out_path, bbox_inches=\"tight\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pH plots\n",
    "grassland_plot(\n",
    "    comanche_pH_da,\n",
    "    \"pH\",\n",
    "    \"comanche\",\n",
    "    \"summer_r\",\n",
    "    \"black\",\n",
    "    \"Soil pH Levels at 60-100 cm Depth\",\n",
    ")\n",
    "grassland_plot(\n",
    "    pawnee_pH_da,\n",
    "    \"pH\",\n",
    "    \"pawnee\",\n",
    "    \"summer_r\",\n",
    "    \"black\",\n",
    "    \"Soil pH Levels at 60-100 cm Depth\",\n",
    ")\n",
    "\n",
    "# Create Elevation & Aspect plots\n",
    "grassland_plot(\n",
    "    comanche_elev_da, \n",
    "    \"elev\", \n",
    "    \"comanche\", \n",
    "    \"YlOrBr\", \n",
    "    \"blue\", \n",
    "    \"Elevation\")\n",
    "grassland_plot(\n",
    "    pawnee_elev_da, \n",
    "    \"elev\", \"pawnee\", \n",
    "    \"YlOrBr\", \n",
    "    \"blue\", \n",
    "    \"Elevation\")\n",
    "grassland_plot(\n",
    "    comanche_aspect_da, \n",
    "    \"aspect\", \n",
    "    \"comanche\", \n",
    "    \"PiYG\", \n",
    "    \"red\", \n",
    "    \"Aspect\")\n",
    "grassland_plot(\n",
    "    pawnee_aspect_da, \n",
    "    \"aspect\", \n",
    "    \"pawnee\", \n",
    "    \"PiYG\", \n",
    "    \"red\", \n",
    "    \"Aspect\")\n",
    "\n",
    "# Create precipitation plots\n",
    "grassland_plot(\n",
    "    pawnee_CCSM4_rcp45_da.mean(\"time\"),\n",
    "    \"rcp45\",\n",
    "    \"pawnee\",\n",
    "    \"Blues\",\n",
    "    \"black\",\n",
    "    \"RCP 4.5 Precipitation\",\n",
    ")\n",
    "grassland_plot(\n",
    "    pawnee_CCSM4_rcp85_da.mean(\"time\"),\n",
    "    \"rcp85\",\n",
    "    \"pawnee\",\n",
    "    \"Blues\",\n",
    "    \"black\",\n",
    "    \"RCP 8.5 Precipitation\",\n",
    ")\n",
    "grassland_plot(\n",
    "    comanche_CCSM4_rcp45_da.mean(\"time\"),\n",
    "    \"rcp45\",\n",
    "    \"comanche\",\n",
    "    \"Blues\",\n",
    "    \"black\",\n",
    "    \"RCP 4.5 Precipitation\",\n",
    ")\n",
    "grassland_plot(\n",
    "    comanche_CCSM4_rcp85_da.mean(\"time\"),\n",
    "    \"rcp85\",\n",
    "    \"comanche\",\n",
    "    \"Blues\",\n",
    "    \"black\",\n",
    "    \"RCP 8.5 Precipitation\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
